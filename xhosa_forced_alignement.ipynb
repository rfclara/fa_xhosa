{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rfclara/fa_xhosa/blob/main/xhosa_forced_alignement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aligning transcriptions and annotations - Xhosa corpus\n",
        "\n"
      ],
      "metadata": {
        "id": "FffJ6hD7dVqw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jKa71Y6_VYK"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The pourpose of this notebook is to align the interlinear glosses with the audio, from a transcribed corpus in Xhosa, one of the official languages of South Africa and Zimbabwe.\n",
        "\n",
        "The transcription of this corpus are not aligned with the speech. We will use [CCT forced alignement](https://pytorch.org/audio/main/tutorials/ctc_forced_alignment_api_tutorial.html) in order to cut the recording into small chunks and get the timestamps corresponding to their transcriptions.\n",
        "\n",
        "\n",
        "Here, we will follow the necessary steps to prepare the data and automatically assign time stamps to each sentence."
      ],
      "metadata": {
        "id": "GfrP1cKUDhAo"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHqkn2_OCz4Y"
      },
      "source": [
        "\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://github.com/cawoylel/nlp4all/blob/main/asr/illustrations/forced_aligner.png?raw=true:, width=200\" alt=\"transformer\" width=500 class=\"center\">\n",
        "<br>\n",
        "    <em>\n",
        "    Illustration of the task of Forced Alignement, from nlp4all\n",
        "    </em>\n",
        "</p>\n",
        "\n",
        "[MMS](https://github.com/facebookresearch/fairseq/blob/main/examples/mms/README.md) is a Forced Aligner using a multilingual speech model trained on more than one thousand languages. You can check here if your language is included: https://dl.fbaipublicfiles.com/mms/misc/language_coverage_mms.html\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZM5ZQKY_SEJ"
      },
      "source": [
        "# Installing the dependencies in the virtual environnement\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install libicu-dev pkg-config"
      ],
      "metadata": {
        "id": "SwpHPRFVs032"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddzlqgyTNrVB"
      },
      "outputs": [],
      "source": [
        "!apt-get install libsox-fmt-all sox # needed for processing audio\n",
        "!apt-get install -y ffmpeg\n",
        "!apt install libicu-dev pkg-config # needed for processing text and unicode symbols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8O-nLC2sN3UC"
      },
      "outputs": [],
      "source": [
        "!pip uninstall torch torchaudio -y # we need to install the nightly version of torch\n",
        "!pip install --pre torch torchaudio --index-url https://download.pytorch.org/whl/nightly/cu118\n",
        "\n",
        "!pip install -q sox # for audio processing\n",
        "!pip install -q ICU-Tokenizer # for tokenizing the text\n",
        "!pip install pandas\n",
        "!pip install tensorboardX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2oC8fZIA6MI"
      },
      "source": [
        "In this step, we clone repositories containing code and resources essential for our ASR project. Specifically, we clone the `rfclara/fa_xhosa` repository, and the `isi-nlp/uroman` repository, which provides functionalities for Romanization of text data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ty-GLgwQ_VOn"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/isi-nlp/uroman.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYVw62egXVtj"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/facebookresearch/fairseq.git\n",
        "!cd fairseq\n",
        "#!pip install --editable ./"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "z1bgYtMS7vNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/rfclara/fa_xhosa\n",
        "!mkdir /content/fa_xhosa\n",
        "os.chdir(\"/content/fa_xhosa\")\n",
        "#manually uploading the pytohn files until I set the repository public\n",
        "#from google.colab import files\n",
        "#uploaded = files.upload()"
      ],
      "metadata": {
        "id": "KXE-mpeULtBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepearing the data\n",
        "Getting the audio files and the transcriptions.\n",
        "Before continuing, put every audio and transcription into a folder named `original` and compress it into `original.zip`. I recommend to save the archive into your Drive.\n",
        "\n",
        "`original.zip` should decompress into one folder called `original` containing the audio files and the transcirptions. Each filename must match and differe only by its extension (.wav, .xlsx)\n",
        "\n",
        "example :\n",
        "story_1.wav\n",
        "story_1.xlsx"
      ],
      "metadata": {
        "id": "wqNEaVzM2hAO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(FASTER) **EITHER** give this notebook acces to your drive:\n",
        "run next cell. It will ask for the permission to acces your drive and it will copy the archive from your Drive to the virtual environnement.\n",
        "\n",
        "Make sure `original.zip` is placed directly in the main directory of your Drive."
      ],
      "metadata": {
        "id": "Fj3aZfAmmRm7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Copy the zip file from Google Drive to the Colab environment\n",
        "!cp /content/drive/MyDrive/original.zip /content"
      ],
      "metadata": {
        "id": "MoS9NCsm6Zje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "__OR__ upload *original.zip* directory containing the trancriptions and the recordings directly here. (next cell will ask you to browse the file)"
      ],
      "metadata": {
        "id": "ewxzASa6MDSv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "im1u3ZkLBP0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decompress `original.zip` into /content/xhosa"
      ],
      "metadata": {
        "id": "7oWITZsII1jm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/xhosa\n",
        "!unzip /content/original.zip -d /content/xhosa"
      ],
      "metadata": {
        "id": "MR6CwWhZInT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extracting the transcriptions from the Excel files\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "i8MMjTcoJnV-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/fa_xhosa/extract_transcriptions.py /content/xhosa/original /content/xhosa/ready"
      ],
      "metadata": {
        "id": "RCgQ7jT6_AJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Last cell's last line should display the number of files that were correctly porcessed."
      ],
      "metadata": {
        "id": "HGitaxRZn49B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OPTIONAL**\n",
        "(but probably leads to a better alignement)\n",
        "\n",
        "REMOVING COMMENTS BETWEEN BRACKETS : ex : \\<code-swiching>, \\<laugh>\n"
      ],
      "metadata": {
        "id": "3zkTjgwq8O_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "for f in /content/xhosa/ready/*.txt; do\n",
        "  python /content/fa_xhosa/remove_comments.py $f\n",
        "done"
      ],
      "metadata": {
        "id": "s3xsVjDe8Of1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following cell will display the last 10 lines of the first trancription. Make sure this cell is displaying the expected result before continuing. All transcriptions can be found in /content/xhosa/ready and can be opened by double clicking on them."
      ],
      "metadata": {
        "id": "LId9xxyqyzrM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!tail -n 10 $(ls /content/xhosa/ready/*.txt | head -n 1)"
      ],
      "metadata": {
        "id": "H50h3opOyyuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXa7lmZ-CV0s"
      },
      "source": [
        "### Resampling the audios  <a name=\"resampling\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyZtr8YXCaBR"
      },
      "source": [
        "After downloading the audios, we need to resample them. Many modern speech models only deal with *16 000 sampling*. We will use `ffmpeg` to resample the audios into 16 000. We will also save the resampled audios into `.wav` files."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will save the resampled wav files into a new `ready` directory containing all the extracted transcriptions .txt."
      ],
      "metadata": {
        "id": "rdUS_kHtSR2W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQOR_M2AQqDQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "for file in os.listdir(\"/content/xhosa/original\"):\n",
        "    if file.endswith(\".wav\"):\n",
        "        input_path = f\"/content/xhosa/original/{file}\"\n",
        "        output_path = f\"/content/xhosa/ready/{os.path.splitext(file)[0]}.wav\"\n",
        "        !ffmpeg -i \"{input_path}\" -ac 1 -ar 16000 \"{output_path}\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHPQxYv3M9oq"
      },
      "source": [
        "## Neural Forced Alignment  <a name=\"aligner\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using [torchaudio.functional.forced_align()](https://pytorch.org/audio/stable/generated/torchaudio.functional.forced_align.html#torchaudio-functional-forced-align) the following cell will automatically align each line of the transcription with its corresponding time in the audio file. This step may take some minutes/hours depending on the length of the corpus."
      ],
      "metadata": {
        "id": "dDdfrfZHu9b9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOGlte_SOe8T"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "input_folder=/content/xhosa/ready\n",
        "output_folder=/content/xhosa/aligned\n",
        "cd /content/fairseq/\n",
        "for audio in $input_folder/*.wav; do\n",
        "  filename=\"$(basename \"$audio\")\"\n",
        "  stem=${filename%.*}\n",
        "  output_path=$output_folder/$stem\n",
        "  rm -rf $output_path\n",
        "  python -m examples.mms.data_prep.align_and_segment \\\n",
        "  --audio_filepath $input_folder/$stem.wav \\\n",
        "  --text_filepath $input_folder/$stem.txt \\\n",
        "  --lang xho \\\n",
        "  --outdir $output_path \\\n",
        "  --uroman /content/uroman/uroman\n",
        "done"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The two following cells allow you to download 'aligned' folder containing, for each original audio file, a manifest.json (timestamps) and every audio chunk in .flac format."
      ],
      "metadata": {
        "id": "AVf-OQ2Fuh8X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Converting the aligned transcriptions to .TextGrid\n",
        "So you can open it in Praat or convert it to .eaf or any other compatible format."
      ],
      "metadata": {
        "id": "_FBwOGuk160G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install textgrid"
      ],
      "metadata": {
        "id": "VUZLfVDL_o2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Add timestamps to Excel files."
      ],
      "metadata": {
        "id": "M4V2SM301e4i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Renaming manifest.json to match original filenames and moving them into `aligned` dir."
      ],
      "metadata": {
        "id": "hsq1CrVVXrG7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "input_directory=\"/content/xhosa/aligned/\"\n",
        "\n",
        "find \"$input_directory\" -type f -name \"manifest.json\" | while IFS= read -r manifest; do\n",
        "  # Extract the directory of the manifest and the name of the subdirectory containing the manifest\n",
        "  manifest_directory=$(dirname \"$manifest\")\n",
        "  subdirectory_name=$(basename \"$manifest_directory\")\n",
        "\n",
        "  # Move and rename the manifest file\n",
        "  mv \"$manifest\" \"/content/xhosa/aligned/$subdirectory_name.json\"\n",
        "done"
      ],
      "metadata": {
        "id": "Kb5VRrdG22hj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "%%shell\n",
        "excel_directory=\"/content/xhosa/original\"\n",
        "aligned_directory=\"/content/xhosa/aligned\"\n",
        "for excel_file in $excel_directory/*.xlsx; do\n",
        "  # Extract the filename without extension\n",
        "  base_name=$(basename \"$excel_file\" | sed 's/\\.xlsx//')\n",
        "  # Construct the corresponding JSON file path\n",
        "  json_file=\"$aligned_directory/$base_name.json\"\n",
        "  #\n",
        "  python3 /content/fa_xhosa/add_times_to_excel.py \"$excel_file\" \"$json_file\" \"$aligned_directory/$base_name.xlsx\" # Use correct variable substitution for the output file\n",
        "done"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "XbcE8rViW5y_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install praatio"
      ],
      "metadata": {
        "id": "4cPZPOXrYG8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "input_directory=\"/content/xhosa/aligned/\"\n",
        "output_directory=\"/content/xhosa/aligned/\"\n",
        "\n",
        "# Find all aligned excel files under the input_directory\n",
        "find \"$input_directory\" -type f -name \"*.xlsx\" | while IFS= read -r excel_file; do\n",
        "  # Extract the filename without extension\n",
        "  base_name=$(basename \"$excel_file\" | sed 's/\\.xlsx//')\n",
        "  # Construct the corresponding output file path\n",
        "  output_file_path=\"$output_directory/$base_name.TextGrid\"\n",
        "  # Call the python script with the manifest and output file path\n",
        "  python /content/fa_xhosa/excel_to_textgrid.py \"$excel_file\" -o \"$output_file_path\"\n",
        "\n",
        "  echo \"Processed $excel_file into $output_file_path\"\n",
        "done"
      ],
      "metadata": {
        "id": "RKhxWPlA3D5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/xhosa/aligned.zip /content/xhosa/aligned"
      ],
      "metadata": {
        "id": "zGJWENRBeMJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SAVE** the aligned files into your drive."
      ],
      "metadata": {
        "id": "PkPeUE2RTWqK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "note : aligned.zip decompress into content -> xhosa -> aligned and not into aligned directly."
      ],
      "metadata": {
        "id": "kyhGHxLDcgOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/xhosa/aligned.zip /content/drive/MyDrive/aligned.zip"
      ],
      "metadata": {
        "id": "YE2qj5HGF_gO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Download** aligned files into your computer."
      ],
      "metadata": {
        "id": "fBFKdZ9F26HM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/xhosa/aligned.zip')"
      ],
      "metadata": {
        "id": "ZR6urk7Q22vx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "-jKa71Y6_VYK"
      ],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}